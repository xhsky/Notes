

数据：简单定义，可以获取和存储的信息
大数据：普遍定义，用传统方法或工具不能处理或分析的数据
	一般而言有4个特征：Volume、Velocity、Variety和Value，简称4V
		Volume：大量。就目前技术而言，至少TB级别以下的数据不能称为大数据
		Velocity：高速。对数据的存储、传输等处理速度快
		Variety：多样。指数据包含结构化、半结构化和非结构化的数据。就大数据而言，一般指非结构化的各种数据
		Value：价值。通过挖掘、分析，得到指导业务的insights
		
	数据类型：			
		结构化数据：传统的关系型数据模型，行数据，存储在数据库中，可用二维表结构来表示
			应用场景：互联网电商交易数据、企业ERP系统、财务系统、医疗HIS数据库，政务信息化系统
				结构规整，处理方案较为成熟
		
		非结构化数据：不方便用数据库二维逻辑来表现的数据，各种文档、图片、视频/音频等
			应用场景：视频网站、图片相册、医疗影视系统、教育视频点播、交通视频监控、文件服务器(PDM/FTP)
				可以考虑使用hdfs等文件系统存储
				
		半结构化数据：类似XML，HTML之类，自描述，数据结构与内容混杂在一起
			应用场景：Web搜索引擎存储、教学资源库、档案系统
				可以考虑使用Hbase等典型的Key-Value存储系统
				
		
		

数据可视化：
	指通过图表将若干数字以直观的方式呈现给用户。如各种二维图，但三维图像和动态图也逐渐被用来展示数据
数据分析：
	指通过统计学手段，从数据中精练出对现实的描述(如针对关系型数据表中以table形式存储的数据，按照某些指定的列进行分组，计算不同组的均值、方差、分布等。
	再以可视化的方式将结果呈现出来。目前的数据分析都是包括数据可视化的)
数据仓库：
	数据仓库是一个面向主题的、集成的、时变的、非易失的数据集合。
数据挖掘：
	主要是在传统统计学的基础上，结合机器学习的算法，对数据进行更深层次的分析，并从中获取一些传统统计学方法无法提供的Insights(预测)
	机器学习的算法主要有回归分析、关联规划、分类、聚类、神经网络、决策树等。

	数据挖据的基本步骤：
		1.数据清理：消除噪声和删除不一致数据
		2.数据集成：多种数据源可以组合在一起
		3.数据选择：从数据库中提取与分析任务相关的数据
		4.数据变换：通过汇总或聚集操作，把数据变换和统一成适合挖掘的形式
		5.数据挖掘：基本步骤，使用智能方法提取数据模式
		6.模式评估：根据某种兴趣度量，识别知识的真正有趣模式
		7.知识表示：使用可视化和知识表示技术，向用户提供挖掘的知识

	数据管理系统的发展：
						-	OLTP(联机事务处理)：主要执行联机事务和查询处理，覆盖了单位的大部分日常操作，如购物，库存，工资等					
		数据库管理系统     
						-	OLAP(联机分析处理)：在数据分析和决策方面为用户提供服务。
商业智能：(Business Intelligence，BI)：
	是一个统称，指的是用于支持定制业务决策的技能、流程、技术、应用和实践。商业智能对当前数据或历史数据进行分析，在理想情况下
	辅助决策者定制未来的业务决策。从技术层面上讲，商业智能不是什么新技术，它只是数据仓库、OLAP等技术的综合运用
	
	
传统数据库和大数据的比较
	1. 最基本的区别：数据规模、数据类型、产生模式。
	2. 处理对象的变化：传统的数据库中数据仅作为处理对象，而在大数据时代，要将数据作为一种资源来辅助解决其他诸多领域的问题。
	3. 处理工具的改变：从以计算为中心转变到以数据处理为中心。	

大数据技术：
	抽象而言，各种大数据技术无外乎分布式存储 + 并行计算。具体体现为各种分布式文件系统和建立在其上的并行运算框架。这些软件程序都部署在多个相
	互连通、统一管理的物理或虚拟运算节点之上，形成集群


	·Hadoop 1.0
		当前最知名的大数据技术
		简单描述Hadoop原理：数据分布式存储，运算程序被发派到各个数据节点进行分别运算（Map），再将各个节点的运算结果进行合并归一（Reduce），生
		成最终结果。相对于动辄TB级别的数据，计算程序一般在KB – MB的量级，这种移动计算不移动数据的设计节约了大量网络带宽和时间，并使得运算过程
		可以充分并行化
	·Hadoop 2.0
		解决了第一代中的master的单点故障和性能瓶颈。引入了一个资源管理平台的组件(Yarn)，通过这个组件，Hadoop可以共用底层存储(HDFS)
		计算框架采取可插拔式的配置，支持Storm，Spark等其他开源计算框架。即同样的集群既可以做批量处理也可做流处理甚至是MPI(大规模并行计算)
	·Storm
		Hadoop虽好，却有其“死穴”.其一：它的运算模式是批处理。这对于许多有实时性要求的业务就无法做到很好的支持。因此，Twitter推出了他们自己的
		基于流的运算框架--Storm.不同于Hadoop一次性处理所有数据并得出统一结果的作业（job），Storm对源源导入的数据流进行持续不断的处理，随时得出
		增量结果。
	·Spark
		Hadoop的另一个致命弱点是：它的所有中间结果都需要进行硬盘存储，I/O消耗巨大，这就使得它很不适合多次迭代的运算。而大多数机器学习算法，恰
		恰要求大量迭代运算。Spark框架的分布式运算的中间过程全部内存存储，由此在迭代计算上大大提高了效率。也因此成为了Hadoop的强有力竞争者
	·NoSQL数据库
		NoSQL数据库可以泛指非关系型数据库，不过一般用来指称那些建立在分布式文件系统（例如HDFS）之上，基于key-value对的数据管理系统。相对于传统
		的关系型数据库，NoSQL数据库中存储的数据无需主键和严格定义的schema.于是，大量半结构化、非结构化数据可以在未经清洗的情况下直接进行存储。
		这一点满足了处理大量、高速、多样的大数据的需求。当前比较流行的NoSQL数据库有MongoDB,Redis,Cassandra,HBase等
		为了兼容之前许多运行在关系型数据库上的业务逻辑，有很多在NoSQL数据库上运行SQL的工具涌现出来，最典型的例如Hive和Pig,它们将用户的SQL语句
		转化成MapReduce作业，在Hadoop上运行
		
大数据的处理模式
	1.流处理：直接处理
		主要应用场景：网页点击的实时统计、传感器网络、金融中的高频交易等
		由于响应时间的要求，流处理的过程基本在内存中完成，其处理方式更多地依赖于在内存中设计巧妙的概要数据结构(synopsis data structure)，内存容
		量是限制流处理模型的一个主要瓶颈。以PCM（相变存储器）为代表的储存级内存(storage class memory, SCM)设备的出现或许可以使内存未来不再成为
		流处理模型的制约。现在流处理比较代表性的开源系统如Twitter的Storm、Yahoo的S4以及Linkedin的Kafka22等
	2.批处理：先存储后处理
		MapReduce模型首先将用户的原始数据源进行分块，然后分别交给不同的Map任务区处理。Map任务从输入中解析出健/值(Key/Value)对集合,然后对这些集合
		执行用户自行定义的Map函数得到中间结果，并将该结果写入本地硬盘。Reduce任务从硬盘上读取数据之后会根据Key值进行排序，将具有相同 Key值的组织
		在一起。最后用户自定义的Reduce函数会作用于这些排好序的结果并输出最终结果。
		从MapReduce的处理过程我们可以看出MapReduce的核心设计思想在于:
			·将问题分而治之
			·把计算推到数据而不是把数据推到计算,有效地避免数据传输过程中产生的大量通信开销。
		MapReduce模型简单，且现实中很多问题都可用MapReduce模型来表示。因此该模型公开后立刻受到极大的关注，并在生物信息学、文本挖掘等领域得到广
		泛的应用
		
	无论是流处理还是批处理都是大数据处理的可行思路。大数据的应用类型很多，在实际的大数据处理中常常并不是简单地只使用其中的某一种而是将二者结合起来	
		
数据库一般存储在线交易数据，数据仓库存储的一般是历史数据		
		
		
		
云计算的目的：通过互联网更好地调用、扩展和管理计算及存储资源和能力，以节省企业的IT 部署成本，其处理对象是IT 资源、处理能力和各种应用。
	云计算从根本上改变了企业的 IT 架构，产业发展的主要推动力量是存储及计算设备的生产厂商和拥有计算及存储资源的企业
		
大数据的目的：充分挖掘海量数据中的信息，发现数据中的价值，其处理对象是各种数据。大数据使得企业从“业务驱动”转变为“数据驱动”，从而改
	变了企业的业务架构，其直接受益者不是 IT 部门，而是业务部门或企业CEO，产业发展的主要推动力量是从事数据存储与处理的软件厂商和拥有大量
	数据的企业	
		
		
用户向数据库写入数据的方式：
	1.装载外部数据
	2.将一个查询的输出结果写入
	3.使用update，insert等语句
	
写时模式：schema on write
	数据在写入数据库时对模式进行检查
读时模式：schema on read
	不会在数据加载时进行验证，而在查询时进行
	
		
		
		
列存和行存：
	列存：
		以列为单位做数据存储，每个列单独一个cell来存储数据
		列式存储适合压缩，在分析上要优于行式存储，且在查询时要尽量按需查找而非整行去获取
		列式数据库对分布式支持友好
	列式引擎：
		分类：
			Parquet
			ORC
	行存：
		以行为单位做数据存储，把一行数据作为一个整体来存储
		行存适合随机查找，且大多提供二级索引。在整行数据的读取上要优于列式存储。
		行式存储不适合扫描
		行式数据库提供ACID和事务
		
		
		
		
涂子沛先生的《大数据》，从美国政府的数据信仰、政策和实践娓娓道来，让中国政坛和知识精英接受了一次思维洗礼
维克托.迈尔.舍恩伯格先生的《大数据时代》，则是系统论述大数据理念的奠基之作。如果说前者着力于发蒙—大数据可以做什么，后者则注重解惑—大数据该怎么做	
		
		
		
		
	
Benchmark
	组成
		数据集：
			·结构化数据
			·半结构化数据
			·非结构化数据
			
		工作负载
			·密集型计算类型
				·CPU密集型计算
				·I/O密集型计算
				·网络密集型计算
			·计算范式
				·批处理
				·流计算
				·图计算
				·机器学习
			·计算延迟
				·在线计算
				·离线计算
				·实时计算
			·应用领域
				·搜索引擎
				·社交网络
				·电子商务
				·地理位置服务
				·媒体、游戏
				
		度量指标
			·架构角度
				·浮点型操作密度
				·整数型操作密度
				·指令中断
				·cache命中率(L1 miss、L2 miss、L3 miss)
				·TLB命中
			·spark系统的执行时间和吞吐量角度
				·Job作业执行时间
				·Job吞吐量
				·Stage执行时间
				·Stage吞吐量
				·Task执行时间
				·Task吞吐量
			·从spark系统资源利用率角度
				·内存在指定时间段的利用率
				·CPU在指定时间段的利用率
				·磁盘在指定时间段的利用率
				·网络带宽在指定时间段的利用率
			·扩展性的角度
				·数据量扩展
				·集群节点数扩展(scale out)
				·单机性能扩展(scale up)
		
		使用：
			Hibench、BigDataBench、TPC-DS
		
		
		
		
	
	
Spark
	伯克利大学AMPLab开发了BDAS(Berkeley Data Analytics Stack)的数据分析栈
		用内存分布式大数据计算引擎Spark替代原有的Mapreduce
		上层通过Spark SQL/Shark 替代Hive等数据仓库
		Spark Streaming替代Storm 等流式计算框架
		GraphX替换Graph Lab等大规模计算框架
		MLib替换Mahout等机器学习框架
	
	
	
压缩：
	Snappy：C++的用来压缩和解压缩的开发包，不兼容其他压缩格式。旨在提供高速压缩速度和合理的压缩率。Snappy 比 zlib 更快，但文件相对要大 20% 到 100%。在 64位模式的 Core i7 处理器上，
		可达每秒 250~500兆的压缩速度。
	Gzip：是一个GNU自由软件的文件压缩程序，gzip命令对文本文件有60%～70%的压缩率
	Bzip2：
	xz
	LZO：是致力于解压速度的一种数据压缩算法
	Deflate：比bzip2压缩更大的算法	
		

 
> set password for 'root'@'localhost' = password(''); 